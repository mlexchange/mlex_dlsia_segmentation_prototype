{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMSNet Ensemble Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook needs to be moved to the parent directory in order to execute. (imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from    src.network         import  build_network\n",
    "from    src.parameters      import  MSDNetParameters, TUNetParameters, TUNet3PlusParameters\n",
    "from    src.seg_utils       import  train_val_split, train_segmentation\n",
    "from    src.tiled_dataset   import  TiledDataset\n",
    "import  torch\n",
    "import  torch.nn        as      nn\n",
    "import  torch.optim     as      optim\n",
    "from    torchvision     import  transforms\n",
    "from    src.utils           import  create_directory\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from dlsia.core.train_scripts import segmentation_metrics\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the YAML file for all parameters\n",
    "yaml_path = 'example_yamls/example_smsnet_ensemble.yaml'\n",
    "with open(yaml_path, 'r') as file:\n",
    "    # Load parameters\n",
    "    parameters = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = parameters['model_parameters']\n",
    "model_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TiledDataset(\n",
    "        data_tiled_uri=parameters['data_tiled_uri'],\n",
    "        data_tiled_api_key=parameters['data_tiled_api_key'],\n",
    "        mask_tiled_uri=parameters['mask_tiled_uri'],\n",
    "        mask_tiled_api_key=parameters['mask_tiled_api_key'],\n",
    "        qlty_window=model_parameters['qlty_window'],\n",
    "        qlty_step=model_parameters['qlty_step'],\n",
    "        qlty_border=model_parameters['qlty_border'],\n",
    "        transform=transforms.ToTensor()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.mask_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.mask_client_one_up.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for n in range(3):\n",
    "    plt.imshow(dataset[n])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.mask_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    elem = batch[0]\n",
    "    print(f'elem type: {type(elem)}')\n",
    "    first_data = elem[0]\n",
    "    print(f'first_data_size: {first_data.shape}')\n",
    "    if isinstance(elem, tuple) and elem[0].ndim == 4:\n",
    "        data, mask = zip(*batch)\n",
    "        concated_data = torch.cat(data, dim=0) # concat on the first dim without introducing another dim -> keep in the 4d realm\n",
    "        concated_mask = torch.cat(mask, dim=0)\n",
    "        print(f'concated_data shape: {concated_data.shape}')\n",
    "        print(f'concated_mask shape: {concated_mask.shape}')\n",
    "        return concated_data, concated_mask\n",
    "    elif isinstance(elem, torch.Tensor) and elem.ndim == 4:\n",
    "        print(f'batch size: {len(batch)}')\n",
    "        concated_data = torch.cat(batch, dim=0) # concat on the first dim without introducing another dim -> keep in the 4d realm\n",
    "        print(f'concated_data shape: {concated_data.shape}')\n",
    "        return concated_data\n",
    "    else:  # Fall back to `default_collate` as suggested by PyTorch documentation\n",
    "        return default_collate(batch)\n",
    "\n",
    "def train_val_split(dataset, parameters):\n",
    "    '''\n",
    "    This funnction splits the given tiled_dataset object into the train set and val set using torch's built in random_split function.\n",
    "\n",
    "    Caution: the random_split does not taken class balance into account. Future upgrades for that direction would requrie sampler from torch.\n",
    "    '''\n",
    "\n",
    "    # Set Dataloader parameters (Note: we randomly shuffle the training set upon each pass)\n",
    "    train_loader_params = {'batch_size': parameters['batch_size_train'],\n",
    "                        'shuffle': parameters['shuffle_train']}\n",
    "    val_loader_params = {'batch_size': parameters['batch_size_val'],\n",
    "                        'shuffle': parameters['shuffle_val']}\n",
    "\n",
    "    # Build Dataloaders\n",
    "    val_pct = parameters['val_pct']\n",
    "    val_size = int(val_pct*len(dataset))\n",
    "    print(f'length of dataset: {len(dataset)}')\n",
    "    print(f'length of val_size: {val_size}')\n",
    "    if len(dataset) == 1:\n",
    "        train_loader = DataLoader(dataset, **train_loader_params, collate_fn=custom_collate)\n",
    "        val_loader = None\n",
    "    elif val_size == 0:\n",
    "        train_size = len(dataset) - 1\n",
    "        train_data, val_data = random_split(dataset, [train_size, 1])\n",
    "        print(f'train_data size: {len(train_data)}')\n",
    "        train_loader = DataLoader(train_data, **train_loader_params, collate_fn=custom_collate)\n",
    "        val_loader = DataLoader(val_data, **val_loader_params, collate_fn=custom_collate)\n",
    "    else:\n",
    "        train_size = len(dataset) - val_size\n",
    "        train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "        train_loader = DataLoader(train_data, **train_loader_params, collate_fn=custom_collate)\n",
    "        val_loader = DataLoader(val_data, **val_loader_params, collate_fn=custom_collate)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = train_val_split(dataset, model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlsia.core.networks import sms3d, smsnet\n",
    "from dlsia.core import helpers\n",
    "\n",
    "def construct_2dsms_ensembler(n_networks,\n",
    "                              in_channels,\n",
    "                              out_channels,\n",
    "                           layers,\n",
    "                           alpha = 0.0,\n",
    "                           gamma = 0.0,\n",
    "                           hidden_channels = None,\n",
    "                           dilation_choices = [1,2,3,4],\n",
    "                           P_IL = 0.995,\n",
    "                           P_LO = 0.995,\n",
    "                           P_IO = True,\n",
    "                           parameter_bounds = None,\n",
    "                           max_trial=100,\n",
    "                           network_type=\"Regression\",\n",
    "                           parameter_counts_only = False\n",
    "                           ):\n",
    "\n",
    "    networks = []\n",
    "\n",
    "    layer_probabilities = {\n",
    "        'LL_alpha': alpha,\n",
    "        'LL_gamma': gamma,\n",
    "        'LL_max_degree': layers,\n",
    "        'LL_min_degree': 1,\n",
    "        'IL': P_IL,\n",
    "        'LO': P_LO,\n",
    "        'IO': P_IO,\n",
    "    }\n",
    "\n",
    "\n",
    "    if parameter_counts_only:\n",
    "        assert parameter_bounds is None\n",
    "\n",
    "    if hidden_channels is None:\n",
    "        hidden_channels = [ 3*out_channels ]\n",
    "\n",
    "    for _ in range(n_networks):\n",
    "        ok = False\n",
    "        count = 0\n",
    "        while not ok:\n",
    "            count += 1\n",
    "            this_net = smsnet.random_SMS_network(in_channels=in_channels,\n",
    "                                                    out_channels=out_channels,\n",
    "                                                    layers=layers,\n",
    "                                                    dilation_choices=dilation_choices,\n",
    "                                                    hidden_out_channels=hidden_channels,\n",
    "                                                    layer_probabilities=layer_probabilities,\n",
    "                                                    sizing_settings=None,\n",
    "                                                    dilation_mode=\"Edges\",\n",
    "                                                    network_type=network_type,\n",
    "                                                    )\n",
    "            pcount = helpers.count_parameters(this_net)\n",
    "            if parameter_bounds is not None:\n",
    "                if pcount > min(parameter_bounds):\n",
    "                    if pcount < max(parameter_bounds):\n",
    "                        ok = True\n",
    "                        networks.append(this_net)\n",
    "                if count > max_trial:\n",
    "                    print(\"Could not generate network, check bounds\")\n",
    "            else:\n",
    "                ok = True\n",
    "                if parameter_counts_only:\n",
    "                    networks.append(pcount)\n",
    "                else:\n",
    "                    networks.append(this_net)\n",
    "    return networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ensemble = construct_2dsms_ensembler(\n",
    "                              n_networks=3,\n",
    "                              in_channels=1,\n",
    "                              out_channels=3,\n",
    "                              layers=5,#<USER CHOICE, LIMIT FROM 5 to say 20>,\n",
    "                              alpha = 0.0, #KEEP AS IS\n",
    "                              gamma = 0.0, # KEEP AS IS\n",
    "                              hidden_channels = None, #<USER CHOICE, LIMIT FROM 3 to 20>\n",
    "                              dilation_choices = [1,2,3,4,5],\n",
    "                              parameter_bounds = None, # LEAVE AS IS\n",
    "                              max_trial=10,\n",
    "                              network_type=\"Classification\", # SET TO \"Classification\" for segmentation task\n",
    "                              parameter_counts_only = False, # LEAVE AS IS\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(net_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criterion and optimizer\n",
    "criterion = getattr(nn, model_parameters['criterion'])\n",
    "criterion = criterion(weight=model_parameters['weights'],\n",
    "                        ignore_index=-1, \n",
    "                        size_average=None\n",
    "                        )    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for idx, net in enumerate(net_ensemble):\n",
    "    optimizer = getattr(optim, model_parameters['optimizer'])\n",
    "    optimizer = optimizer(net.parameters(), lr = model_parameters['learning_rate'])\n",
    "    net, results = train_segmentation(\n",
    "        net,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        model_parameters['num_epochs'],\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        device,\n",
    "        savepath=parameters['save_path'],\n",
    "        saveevery=None,\n",
    "        scheduler=None,\n",
    "        show=0,\n",
    "        use_amp=False,\n",
    "        clip_value=None\n",
    "    )\n",
    "    # Save network parameters\n",
    "    model_params_path = f\"{parameters['save_path']}/{parameters['uid']}_SMSNet{idx}.pt\"\n",
    "    net.save_network_parameters(model_params_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlsia.core.networks.baggins import model_baggin\n",
    "from dlsia.core.networks.smsnet import SMSNetwork_from_file\n",
    "from    qlty.qlty2D         import  NCYXQuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TiledDataset(\n",
    "        data_tiled_uri=parameters['data_tiled_uri'],\n",
    "        mask_idx=parameters['mask_idx'], # Keeping this for a quick inference for now, in future this will be out with updates from app.\n",
    "        data_tiled_api_key=parameters['data_tiled_api_key'],\n",
    "        qlty_window=model_parameters['qlty_window'],\n",
    "        qlty_step=model_parameters['qlty_step'],\n",
    "        qlty_border=model_parameters['qlty_border'],\n",
    "        transform=transforms.ToTensor()\n",
    "        )\n",
    "\n",
    "# Set Dataloader parameters (Note: we randomly shuffle the training set upon each pass)\n",
    "inference_loader_params = {'batch_size': model_parameters['batch_size_inference'],\n",
    "                            'shuffle': model_parameters['shuffle_inference']}\n",
    "# Build Dataloaders\n",
    "inference_loader = DataLoader(dataset, **inference_loader_params, collate_fn=custom_collate)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['results/models/uid0013_SMSNet0.pt', 'results/models/uid0013_SMSNet1.pt', 'results/models/uid0013_SMSNet2.pt']\n",
    "list_of_smsnet = []\n",
    "for network in filenames:\n",
    "    list_of_smsnet.append(SMSNetwork_from_file(network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(net, device, inference_loader, qlty_object):\n",
    "\n",
    "    patch_preds = [] # store results for patches\n",
    "    for batch in inference_loader:\n",
    "        with torch.no_grad():\n",
    "            # Necessary data recasting\n",
    "            batch = batch.type(torch.FloatTensor)\n",
    "            batch = batch.to(device)\n",
    "            # Input passed through networks here\n",
    "            mean_map, std_map = net(batch,device=device,return_std=True)\n",
    "            patch_preds.append(mean_map)\n",
    "    \n",
    "    patch_preds = torch.concat(patch_preds)\n",
    "    stitched_result, weights = qlty_object.stitch(patch_preds)\n",
    "    # Individual output passed through argmax to get predictions\n",
    "    seg = torch.argmax(stitched_result.cpu(), dim=1).numpy()\n",
    "    print(f'Result array shape: {seg.shape}')\n",
    "    print(f'Result array type: {type(seg)}')\n",
    "    return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = model_baggin(models=list_of_smsnet, model_type='classification')\n",
    "# mean_map, std_map = ensemble(input_tensor, device=device,return_std=True)\n",
    "qlty_object = NCYXQuilt(X=dataset.data_client.shape[-1], \n",
    "                        Y=dataset.data_client.shape[-2],\n",
    "                        window = (model_parameters['qlty_window'], model_parameters['qlty_window']),\n",
    "                        step = (model_parameters['qlty_step'], model_parameters['qlty_step']),\n",
    "                        border = (model_parameters['qlty_border'], model_parameters['qlty_border'])\n",
    "                            )\n",
    "seg = segment(ensemble, device, inference_loader, qlty_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seg[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlsia_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
