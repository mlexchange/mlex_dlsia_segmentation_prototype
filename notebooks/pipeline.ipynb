{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from dlsia.core import helpers, train_scripts\n",
    "from dlsia.core.networks import msdnet, tunet, tunet3plus\n",
    "from dlsia.test_data.two_d import random_shapes\n",
    "from dlsia.viz_tools import plots\n",
    "from dlsia.core.train_scripts import segmentation_metrics\n",
    "\n",
    "from tiled.client import from_uri\n",
    "from tiled.client import show_logs, hide_logs\n",
    "from tiled.utils import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECON_TILED_URI = os.getenv('RECON_TILED_URI')\n",
    "RECON_TILED_API_KEY = os.getenv('RECON_TILED_API_KEY')\n",
    "MASK_TILED_URI = os.getenv('MASK_TILED_URI')\n",
    "MASK_TILED_API_KEY = os.getenv('MASK_TILED_API_KEY')\n",
    "SEG_TILED_URI = os.getenv('SEG_TILED_URI')\n",
    "SEG_TILED_API_KEY = os.getenv('SEG_TILED_API_KEY')\n",
    "UID = 'uid0001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TiledDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            recon_uri,\n",
    "            mask_uri,\n",
    "            seg_uri,\n",
    "            mask_idx,\n",
    "            recon_api_key=None,\n",
    "            mask_api_key=None,\n",
    "            seg_api_key=None,\n",
    "            shift=0,\n",
    "            transform=None):\n",
    "        '''\n",
    "        Args:\n",
    "            recon_uri:      str,    Tiled URI of the reconstruction\n",
    "            mask_uri:       str,    Tiled URI of mask\n",
    "            seg_uri:        str,    Tiled URI of segmentation results\n",
    "            mask_idx:       list,   List for slice indexs that maps the mask to corresponding recon images  \n",
    "            recon_api_key:  str,    Tiled API key for reconstruction access\n",
    "            mask_api_key:   str,    Tiled API key for mask access\n",
    "            seg_api_key:    str,    Tiled API key for segmentation access\n",
    "            shift:          int,    Optional shift for pixel values in masks to bring down the class id to start from 0, (and -1 for unlabeled pixles)\n",
    "            transform:      callable, if not given return PIL image\n",
    "\n",
    "        Return:\n",
    "            ml_data:        tuple, (recon_tensor, mask_tensor)\n",
    "        '''\n",
    "        self.recon_client = from_uri(recon_uri, api_key=recon_api_key)\n",
    "        self.mask_client = from_uri(mask_uri, api_key=mask_api_key)\n",
    "        self.seg_client = from_uri(seg_uri, api_key=seg_api_key)\n",
    "        self.mask_idx = list(mask_idx)\n",
    "        self.shift = int(shift)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask_client)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        recon = self.recon_client[self.mask_idx[idx],]\n",
    "        mask = self.mask_client[idx,].astype('int') - shift # Conversion to int is needed as switching unlabeled pixels to -1 would cause trouble in uint8 format\n",
    "        if self.transform:\n",
    "            return self.transform(recon), mask\n",
    "        else:\n",
    "            return recon, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_segmentation(net, trainloader, validationloader, NUM_EPOCHS,\n",
    "                       criterion, optimizer, device,\n",
    "                       savepath=None, saveevery=None,\n",
    "                       scheduler=None, show=0,\n",
    "                       use_amp=False, clip_value=None):\n",
    "    \"\"\"\n",
    "    Loop through epochs passing images to be segmented on a pixel-by-pixel\n",
    "    basis.\n",
    "\n",
    "    :param net: input network\n",
    "    :param trainloader: data loader with training data\n",
    "    :param validationloader: data loader with validation data\n",
    "    :param NUM_EPOCHS: number of epochs\n",
    "    :param criterion: target function\n",
    "    :param optimizer: optimization engine\n",
    "    :param device: the device where we calculate things\n",
    "    :param savepath: filepath in which we save networks intermittently\n",
    "    :param saveevery: integer n for saving network every n epochs\n",
    "    :param scheduler: an optional schedular. can be None\n",
    "    :param show: print stats every n-th epoch\n",
    "    :param use_amp: use pytorch automatic mixed precision\n",
    "    :param clip_value: value for gradient clipping. Can be None.\n",
    "    :return: A network and run summary stats\n",
    "    \"\"\"\n",
    "\n",
    "    train_loss = []\n",
    "    F1_train_trace_micro = []\n",
    "    F1_train_trace_macro = []\n",
    "\n",
    "    # Skip validation steps if False or None loaded\n",
    "    if validationloader is False:\n",
    "        validationloader = None\n",
    "    if validationloader is not None:\n",
    "        validation_loss = []\n",
    "        F1_validation_trace_micro = []\n",
    "        F1_validation_trace_macro = []\n",
    "\n",
    "    best_score = 1e10\n",
    "    best_index = 0\n",
    "    best_state_dict = None\n",
    "\n",
    "    if savepath is not None:\n",
    "        if saveevery is None:\n",
    "            saveevery = 1\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_train_loss = 0.0\n",
    "        running_F1_train_micro = 0.0\n",
    "        running_F1_train_macro = 0.0\n",
    "        tot_train = 0.0\n",
    "\n",
    "        if validationloader is not None:\n",
    "            running_validation_loss = 0.0\n",
    "            running_F1_validation_micro = 0.0\n",
    "            running_F1_validation_macro = 0.0\n",
    "            tot_val = 0.0\n",
    "        count = 0\n",
    "\n",
    "        for data in trainloader:\n",
    "            count += 1\n",
    "            noisy, target = data  # load noisy and target images\n",
    "            N_train = noisy.shape[0]\n",
    "            tot_train += N_train\n",
    "\n",
    "            noisy = noisy.type(torch.FloatTensor)\n",
    "            target = target.type(torch.LongTensor)\n",
    "            noisy = noisy.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            if criterion.__class__.__name__ == 'CrossEntropyLoss':\n",
    "                target = target.type(torch.LongTensor)\n",
    "                target = target.to(device).squeeze(1)\n",
    "\n",
    "            if use_amp is False:\n",
    "                # forward pass, compute loss and accuracy\n",
    "                output = net(noisy)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                # backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "            else:\n",
    "                scaler = torch.cuda.amp.GradScaler()\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    # forward pass, compute loss and accuracy\n",
    "                    output = net(noisy)\n",
    "                    loss = criterion(output, target)\n",
    "\n",
    "                # backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # update the parameters\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            # update the parameters\n",
    "            if clip_value is not None:\n",
    "                torch.nn.utils.clip_grad_value_(net.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            tmp_micro, tmp_macro = segmentation_metrics(output, target)\n",
    "\n",
    "            running_F1_train_micro += tmp_micro.item()\n",
    "            running_F1_train_macro += tmp_macro.item()\n",
    "            running_train_loss += loss.item()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # compute validation step\n",
    "        if validationloader is not None:\n",
    "            with torch.no_grad():\n",
    "                for x, y in validationloader:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "                    N_val = y.shape[0]\n",
    "                    tot_val += N_val\n",
    "                    if criterion.__class__.__name__ == 'CrossEntropyLoss':\n",
    "                        y = y.type(torch.LongTensor)\n",
    "                        y = y.to(device).squeeze(1)\n",
    "\n",
    "                    # forward pass, compute validation loss and accuracy\n",
    "                    if use_amp is False:\n",
    "                        yhat = net(x)\n",
    "                        val_loss = criterion(yhat, y)\n",
    "                    else:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            yhat = net(x)\n",
    "                            val_loss = criterion(yhat, y)\n",
    "\n",
    "                    tmp_micro, tmp_macro = segmentation_metrics(yhat, y)\n",
    "                    running_F1_validation_micro += tmp_micro.item()\n",
    "                    running_F1_validation_macro += tmp_macro.item()\n",
    "\n",
    "                    # update running validation loss and accuracy\n",
    "                    running_validation_loss += val_loss.item()\n",
    "\n",
    "        loss = running_train_loss / len(trainloader)\n",
    "        F1_micro = running_F1_train_micro / len(trainloader)\n",
    "        F1_macro = running_F1_train_macro / len(trainloader)\n",
    "        train_loss.append(loss)\n",
    "        F1_train_trace_micro.append(F1_micro)\n",
    "        F1_train_trace_macro.append(F1_macro)\n",
    "\n",
    "        if validationloader is not None:\n",
    "            val_loss = running_validation_loss / len(validationloader)\n",
    "            F1_val_micro = running_F1_validation_micro / len(validationloader)\n",
    "            F1_val_macro = running_F1_validation_macro / len(validationloader)\n",
    "            validation_loss.append(val_loss)\n",
    "            F1_validation_trace_micro.append(F1_val_micro)\n",
    "            F1_validation_trace_macro.append(F1_val_macro)\n",
    "            # Update loss parquet file\n",
    "            if epoch == 0:\n",
    "                table = pd.DataFrame(\n",
    "                    {\n",
    "                        'epoch': [epoch],\n",
    "                        'loss': [loss], \n",
    "                        'val_loss': [val_loss], \n",
    "                        'F1_micro': [F1_micro], \n",
    "                        'F1_macro': [F1_macro],\n",
    "                        'F1_val_micro': [F1_val_micro],\n",
    "                        'F1_val_macro': [F1_val_macro]\n",
    "                    }\n",
    "                    )\n",
    "            else:\n",
    "                table = pd.concat([\n",
    "                    table, \n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                        'epoch': [epoch],\n",
    "                        'loss': [loss], \n",
    "                        'val_loss': [val_loss], \n",
    "                        'F1_micro': [F1_micro], \n",
    "                        'F1_macro': [F1_macro],\n",
    "                        'F1_val_micro': [F1_val_micro],\n",
    "                        'F1_val_macro': [F1_val_macro]\n",
    "                        }\n",
    "                    )\n",
    "                ])\n",
    "        else:\n",
    "            # Update loss parquet file\n",
    "            if epoch == 0:\n",
    "                table = pd.DataFrame({\n",
    "                        'epoch': [epoch],\n",
    "                        'loss': [loss], \n",
    "                        'F1_micro': [F1_micro], \n",
    "                        'F1_macro': [F1_macro]})\n",
    "            else:\n",
    "                table = pd.concat([\n",
    "                    table, \n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                        'epoch': [epoch],\n",
    "                        'loss': [loss], \n",
    "                        'F1_micro': [F1_micro], \n",
    "                        'F1_macro': [F1_macro]\n",
    "                        }\n",
    "                    )\n",
    "                ])\n",
    "        table.to_parquet(savepath+'/losses_per_epoch.parquet', engine='pyarrow')\n",
    "\n",
    "        if show != 0:\n",
    "            learning_rates = []\n",
    "            for param_group in optimizer.param_groups:\n",
    "                learning_rates.append(param_group['lr'])\n",
    "            mean_learning_rate = np.mean(np.array(learning_rates))\n",
    "            if np.mod(epoch + 1, show) == 0:\n",
    "                if validationloader is not None:\n",
    "                    print(\n",
    "                        f'Epoch {epoch + 1} of {NUM_EPOCHS} | Learning rate {mean_learning_rate:4.3e}')\n",
    "                    print(\n",
    "                        f'   Training Loss: {loss:.4e} | Validation Loss: {val_loss:.4e}')\n",
    "                    print(\n",
    "                        f'   Micro Training F1: {F1_micro:.4f} | Micro Validation F1: {F1_val_micro:.4f}')\n",
    "                    print(\n",
    "                        f'   Macro Training F1: {F1_macro:.4f} | Macro Validation F1: {F1_val_macro:.4f}')\n",
    "                else:\n",
    "                    print(\n",
    "                        f'Epoch {epoch + 1} of {NUM_EPOCHS} | Learning rate {mean_learning_rate:4.3e}')\n",
    "                    print(\n",
    "                        f'   Training Loss: {loss:.4e} | Micro Training F1: {F1_micro:.4f} | Macro Training F1: {F1_macro:.4f}')\n",
    "\n",
    "        if validationloader is not None:\n",
    "            if val_loss < best_score:\n",
    "                best_state_dict = net.state_dict()\n",
    "                best_index = epoch\n",
    "                best_score = val_loss\n",
    "        else:\n",
    "            if loss < best_score:\n",
    "                best_state_dict = net.state_dict()\n",
    "                best_index = epoch\n",
    "                best_score = loss\n",
    "\n",
    "            if savepath is not None:\n",
    "                torch.save(best_state_dict, savepath + '/net_best')\n",
    "                print('   Best network found and saved')\n",
    "                print('')\n",
    "\n",
    "        if savepath is not None:\n",
    "            if np.mod(epoch + 1, saveevery) == 0:\n",
    "                torch.save(net.state_dict(), savepath + '/net_checkpoint')\n",
    "                print('   Network intermittently saved')\n",
    "                print('')\n",
    "\n",
    "    if validationloader is None:\n",
    "        validation_loss = None\n",
    "        F1_validation_trace_micro = None\n",
    "        F1_validation_trace_macro = None\n",
    "\n",
    "    results = {\"Training loss\": train_loss,\n",
    "               \"Validation loss\": validation_loss,\n",
    "               \"F1 training micro\": F1_train_trace_micro,\n",
    "               \"F1 training macro\": F1_train_trace_macro,\n",
    "               \"F1 validation micro\": F1_validation_trace_micro,\n",
    "               \"F1 validation macro\": F1_validation_trace_macro,\n",
    "               \"Best model index\": best_index}\n",
    "\n",
    "    net.load_state_dict(best_state_dict)\n",
    "    return net, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_idx = [10, 201, 222, 493]\n",
    "shift = 2\n",
    "data_transform = transforms.ToTensor()\n",
    "\n",
    "dataset = TiledDataset(\n",
    "    recon_uri=RECON_TILED_URI,\n",
    "    mask_uri=MASK_TILED_URI,\n",
    "    seg_uri=SEG_TILED_URI,\n",
    "    mask_idx=mask_idx,\n",
    "    recon_api_key=RECON_TILED_API_KEY,\n",
    "    mask_api_key=MASK_TILED_API_KEY,\n",
    "    seg_api_key=SEG_TILED_API_KEY,\n",
    "    shift = shift,\n",
    "    transform=data_transform\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'TUNet'\n",
    "save_dir = 'models'\n",
    "\n",
    "# Specify batch sizes\n",
    "batch_size_train = 1\n",
    "batch_size_val = 1\n",
    "batch_size_test = 1\n",
    "\n",
    "# Dataset shape\n",
    "recon_shape = np.array(dataset.recon_client.shape)\n",
    "if len(recon_shape)==3:\n",
    "    in_channels = 1\n",
    "    image_shape = recon_shape[1:]\n",
    "else:\n",
    "    in_channels = recon_shape[1]\n",
    "    image_shape = recon_shape[2:]\n",
    "out_channels = 3\n",
    "depth = 4 #<6\n",
    "base_channels = 16 # 8 16 32\n",
    "growth_rate = 2\n",
    "hidden_rate = 1\n",
    "activation = nn.ReLU()\n",
    "normalization = nn.BatchNorm2d  # Change to 3d for volumous data\n",
    "\n",
    "# Training Parameters\n",
    "epochs = 3\n",
    "learning_rate = 1e-2\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "model_path = f'{save_dir}/{UID}_{model}.pt'\n",
    "\n",
    "params = {'batch_size_train': 1,\n",
    "          'shuffle_train': True,\n",
    "          'batch_size_val': 1,\n",
    "          'shuffle_val': True,\n",
    "          'batch_size_test': 1,\n",
    "          'shuffle_test': False,\n",
    "          'val_pct': 0.2,\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(dataset, parameters):\n",
    "    '''\n",
    "    This funnction splits the given tiled_dataset object into the train set and val set using torch's built in random_split function.\n",
    "\n",
    "    Caution: the random_split does not taken class balance into account. Future upgrades for that direction would requrie sampler from torch.\n",
    "    '''\n",
    "\n",
    "    # Set Dataloader parameters (Note: we randomly shuffle the training set upon each pass)\n",
    "    train_loader_params = {'batch_size': parameters['batch_size_train'],\n",
    "                        'shuffle': parameters['shuffle_train']}\n",
    "    val_loader_params = {'batch_size': parameters['batch_size_val'],\n",
    "                        'shuffle': parameters['shuffle_val']}\n",
    "    # Set Dataloader parameters (Note: we randomly shuffle the training set upon each pass)\n",
    "    test_loader_params = {'batch_size': parameters['batch_size_test'],\n",
    "                        'shuffle': parameters['shuffle_test']}\n",
    "\n",
    "    # Build Dataloaders\n",
    "    val_pct = parameters['val_pct']\n",
    "    val_size = int(val_pct*len(dataset))\n",
    "    if len(dataset) == 1:\n",
    "        train_loader = DataLoader(dataset, **train_loader_params)\n",
    "        val_loader = None\n",
    "    elif val_size == 0:\n",
    "        train_size = len(dataset) - 1\n",
    "        train_data, val_data = random_split(dataset, [train_size, 1])\n",
    "        train_loader = DataLoader(train_data, **train_loader_params)\n",
    "        val_loader = DataLoader(val_data, **val_loader_params)\n",
    "    else:\n",
    "        train_size = len(dataset) - val_size\n",
    "        train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "        train_loader = DataLoader(train_data, **train_loader_params)\n",
    "        val_loader = DataLoader(val_data, **val_loader_params)\n",
    "\n",
    "    # Build Dataloaders\n",
    "    test_loader = DataLoader(dataset, **test_loader_params)\n",
    "\n",
    "    print(\"The length of train data is:\",len(train_data))\n",
    "    print(\"The length of validation data is:\",len(val_data))\n",
    "    print(\"The length of inference data is:\",len(dataset))\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train data is: 3\n",
      "The length of validation data is: 1\n",
      "The length of inference data is: 4\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = train_val_split(dataset=dataset, parameters=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  483187\n"
     ]
    }
   ],
   "source": [
    "tunet_model = tunet.TUNet(image_shape=image_shape,\n",
    "                          in_channels=in_channels,\n",
    "                          out_channels=out_channels,\n",
    "                          depth=depth,\n",
    "                          base_channels=base_channels,\n",
    "                          growth_rate=growth_rate,\n",
    "                          hidden_rate=hidden_rate,\n",
    "                          activation=activation,\n",
    "                          normalization=normalization,\n",
    "                         )\n",
    "\n",
    "print('Number of parameters: ', helpers.count_parameters(tunet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device we will compute on:  cpu\n"
     ]
    }
   ],
   "source": [
    "label2ignore = -1\n",
    "criterion = getattr(nn, \"CrossEntropyLoss\")\n",
    "criterion = criterion(ignore_index=label2ignore, size_average=None)\n",
    "\n",
    "# Define optimizers, one per network\n",
    "optimizer_tunet = optim.Adam(tunet_model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = helpers.get_device()\n",
    "print('Device we will compute on: ', device)   # cuda:0 for GPU. Else, CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tibbers/miniforge3/envs/dlsia_seg/lib/python3.9/site-packages/torchvision/transforms/functional.py:152: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Network intermittently saved\n",
      "\n",
      "   Network intermittently saved\n",
      "\n",
      "   Network intermittently saved\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "red"
         },
         "mode": "lines+markers",
         "name": "Training",
         "type": "scatter",
         "x": [
          0,
          1,
          2
         ],
         "xaxis": "x",
         "y": [
          0.9661324818929037,
          0.6412716309229533,
          0.4870605270067851
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines+markers",
         "name": "Validation",
         "type": "scatter",
         "x": [
          0,
          1,
          2
         ],
         "xaxis": "x",
         "y": [
          1.0233851671218872,
          0.8989982604980469,
          0.8138729929924011
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines+markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2
         ],
         "xaxis": "x2",
         "y": [
          0.5054873128732046,
          0.6627050042152405,
          0.654004176457723
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines+markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2
         ],
         "xaxis": "x2",
         "y": [
          0.45744630694389343,
          0.4487946629524231,
          0.4240495562553406
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Loss",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "F1",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "autosize": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "type": "log"
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 128x96 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tunet_model.to(device)   # send network to GPU\n",
    "\n",
    "tunet_model, results = train_segmentation(tunet_model,\n",
    "                                          train_loader,\n",
    "                                          val_loader,\n",
    "                                          epochs,\n",
    "                                          criterion,\n",
    "                                          optimizer_tunet,\n",
    "                                          device,\n",
    "                                          show=5,\n",
    "                                          savepath=save_dir\n",
    "                                          )   # training happens here\n",
    "tunet_model = tunet_model.cpu()\n",
    "\n",
    "fig = plots.plot_training_results_segmentation(results)\n",
    "plt.figure(dpi=20)\n",
    "fig.show()\n",
    "\n",
    "# Save Model\n",
    "tunet_model.save_network_parameters(model_path)\n",
    "\n",
    "# clear out unnecessary variables from device (GPU) memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1760, 1760)\n",
      "int64\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "tunet_model.to(device)   # send network to GPU\n",
    "n = 0\n",
    "cmap='jet'\n",
    "seg = None\n",
    "for batch in test_loader:\n",
    "    with torch.no_grad():\n",
    "        recon, mask = batch\n",
    "        # Necessary data recasting\n",
    "        recon = recon.type(torch.FloatTensor)\n",
    "        mask = mask.type(torch.LongTensor)\n",
    "        recon = recon.to(device)\n",
    "        mask = mask.to(device)#.squeeze(1)\n",
    "\n",
    "        # Input passed through networks here\n",
    "        output_network = tunet_model(recon)\n",
    "        # Individual output passed through argmax to get predictions\n",
    "        preds = torch.argmax(output_network.cpu().data, dim=1).numpy()\n",
    "        if seg is None:\n",
    "            seg = preds\n",
    "        else:\n",
    "            seg = np.concatenate((seg, preds), axis = 0)\n",
    "        \n",
    "print(seg.shape)\n",
    "print(seg.dtype)\n",
    "print(np.unique(seg))\n",
    "        \n",
    "# clear out unnecessary variables from device (GPU) memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_seg_to_tiled(seg_result, \n",
    "                      tiled_dataset,\n",
    "                      container_keys,\n",
    "                      model,\n",
    "                      ):\n",
    "    last_container = tiled_dataset.seg_client\n",
    "    for key in container_keys:\n",
    "        if key not in last_container.keys():\n",
    "            last_container = last_container.create_container(key=key)\n",
    "        else:\n",
    "            last_container = last_container[key]\n",
    "\n",
    "    metadata={\n",
    "        'recon_uri': tiled_dataset.recon_client.uri,\n",
    "        'mask_uri': tiled_dataset.mask_client.uri, \n",
    "        'model': model, \n",
    "        }\n",
    "    seg_result = last_container.write_array(key=\"seg_result\", array=seg_result, metadata=metadata)\n",
    "    print(\"Segmentaion result array saved in following uri: \", seg_result.uri)\n",
    "    return seg_result.uri, seg_result.metadata   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentaion result array saved in following uri:  http://0.0.0.0:8888/api/v1/metadata/mlex_store/rec20190524_085542_clay_testZMQ_8bit/results/uid0001/seg_result\n"
     ]
    }
   ],
   "source": [
    "seg_result = seg\n",
    "tiled_dataset = dataset\n",
    "container_keys = [\"mlex_store\", 'rec20190524_085542_clay_testZMQ_8bit', 'results']\n",
    "container_keys.append(UID)\n",
    "\n",
    "seg_result_uri, seg_result_metadata = save_seg_to_tiled(seg_result, tiled_dataset, container_keys, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── mlex_store\n",
      "│   └── user1\n",
      "│       └── rec20190524_085542_clay_testZMQ_8bit\n",
      "│           └── uid0001\n",
      "│               └── mask\n",
      "│                   └── ClassifiedImage_\n",
      "└── reconstruction\n",
      "    └── rec20190524_085542_clay_testZMQ_8bit\n",
      "        └── 20190524_085542_clay_testZMQ_\n"
     ]
    }
   ],
   "source": [
    "tree(dataset.seg_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlsia_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
